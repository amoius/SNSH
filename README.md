# SNSH
Signed Network Representation Learning Algorithm Based on Structural Balance Theory and High-order Mutual Information

基于结构平衡理论和高阶互信息的符号网络表示学习算法

## 摘要
网络表示学习旨在学习给定网络中节点的低维特征向量表示，已经引起了越来越多的关注。然而，绝大多数现有的网络表示学习算法仅仅针对无符号网络来设计。本文提出了一种基于结构平衡理论的符号网络表示学习框架SNSH，通过反转符号网络中的正负关系生成负图，来对符号网络中隐含的高阶互信息进行挖掘。该方法旨在通过加强的社会平衡理论，来模拟符号网络的局部隐含特征，并通过节点局部嵌入、网络全局结构和节点特征属性三者之间的高阶互信息，得到更全面的符合符号网络特性的节点嵌入。

## 简介
Here we provide an implementation of SNSH, along with a minimal execution example (on the Guinea dataset). The repository is organised as follows:
- `input/` 包含输入数据集;
- `output/` 包含输出结果;
- `layers/` 包含SNSH算法互信息层的实现;

## 算法整体框架
<img width="297" alt="image" src="https://user-images.githubusercontent.com/74093803/193469610-18885226-24f4-4a1f-898d-c0efff950281.png">


## 补充说明的算法细节
### 1. 负采样
传统的基于词向量模型的嵌方式如DeepWalk，node2vec等，都采用随机游走的方式构造节点对，对于符号网络，基于下面两个理由，我们认为随机游走并不适用于符号网络。
首先，目标节点与窗口节点之间的关系难以确定。基于结构平衡理论，可以用节点之间的路径来确定节点之间的符号，节点之间的预测关系可以使用路径符号的乘积来计算。但节点之间往往存在多条不同的路径，对于符号网络来说，通过不同路径计算得到的关系也不一定相同，这样就会导致在模型中，节点对之间的关系产生矛盾。
其次，节点之间的高阶关系的效用难以确定，且会产生大量冗余数据，导致算法复杂度上升。基于六度空间理论，一个人能与世界上大部分人在六步之间建立联系，但实际上两者之间大概率并不熟悉。比如，在现实生活中，一个人往往仅与身边的朋友比较熟悉，对朋友的朋友有一定了解，但对朋友的朋友的朋友，经常一无所知，更谈不上关系如何。因此，我们认为3跳及以上的高阶邻居节点，对目标节点的符号信息影响很小。
综上可知，基于随机游走确定的高阶邻居节点，在拟合节点符号关系时，不但其嵌入效果存疑，反而还会增加大量无效计算。对比一般的随机游走方法，该方法仅针对所有直接相连节点对，通过为节点构造一阶正邻居集合与一阶负邻居集合，来构造负采样池，以图在局部上拟合节点的符号信息。
### 2. 虚拟节点
为了方便计算，我们改进了传统的负采样方式，每次仅优化一对节点及确定数目的负样本。例如，当对于节点v_i优化其正关系邻居v_j时，我们在节点v_i的负邻居集\eta_i^-进行负采样，经sigmoid函数映射后，将v_i与v_j的相似度概率设为1，v_i与所有负采样节点的相似度概率设为0。当对于节点v_i优化其负关系邻居v_j时，我们在节点v_i的正邻居集\eta_i^+进行负采样，经sigmoid函数映射后，将v_i与v_j的相似度概率设为0，v_i与所有负采样节点的相似度概率设为1除以负采样数。
有的节点可能不存在负采样，针对这个问题，我们首先定义一个虚拟节点，令虚拟节点与所有节点相连，并建立中立关系，即比朋友更疏远，比敌人更亲近。当负采样节点不存在或数量小于采样数时，我们将虚拟节点加入负采样集，并允许负采样节点重复来进行填充。当负采样节点大于采样数时，我们进行多次采样，以保证优化过程覆盖所有负采样节点。
本模块采用了创新的负采样方式，基于词向量模型及结构平衡理论，对符号网络中的正负关系进行了拟合，最终得到了可以体现符号网络特性分布的p维节点嵌入矩阵X，供后面步骤使用。
### 3. 多次采样
为了提高模型的鲁棒性，我们采用了多次采样的方式，即对于每个节点，我们分别对其正邻居集和负邻居集进行多次采样，每次采样的结果都作为一个训练样本，最终得到的训练样本数目为节点数目的多倍。这样做的好处是，可以使得模型对于每个节点的正负关系都有一定的学习机会，从而提高模型的鲁棒性。

详见代码与论文
